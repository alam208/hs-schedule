name: Scrape MaxPreps → JSON → Pages

on:
  workflow_dispatch:
    inputs:
      date:
        description: 'Tanggal (mm/dd/YYYY), contoh: 10/03/2025'
        required: true
        default: '10/03/2025'
      states:
        description: 'Kode state dipisah koma (kosong = semua), contoh: nj,wy,tx'
        required: false
        default: ''
  # (Opsional) Jalankan otomatis tiap Jumat 17:00 US/Eastern (≈21:00 UTC; sesuaikan DST)
  schedule:
    - cron: '0 21 * * FRI'

permissions:
  contents: write
  pages: write
  id-token: write

# Hanya izinkan 1 run pada satu waktu; run baru akan membatalkan yang lama
concurrency:
  group: scrape-pages
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # Cache pip agar lebih cepat
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('scraper/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-

      # Cache Playwright browsers agar step install lebih cepat di run berikutnya
      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: msplaywright-${{ runner.os }}-chromium

      - name: Install Python deps
        run: pip install -r scraper/requirements.txt

      # Penting: Install Chromium untuk Playwright
      - name: Install Playwright browsers (Chromium)
        run: python -m playwright install --with-deps chromium

      - name: Parse inputs
        id: args
        run: |
          echo "date=${{ github.event.inputs.date }}" >> $GITHUB_OUTPUT
          echo "states=${{ github.event.inputs.states }}" >> $GITHUB_OUTPUT

      # Jalankan scraper
      # Catatan:
      # - LIMIT_PER_STATE: batasi jumlah game per state saat testing (hapus/buat kosong untuk full)
      # - NO_PLAYWRIGHT: set "1" untuk mematikan fallback Playwright saat test cepat (hapus untuk aktifkan lagi)
      - name: Run scraper
        env:
          # LIMIT_PER_STATE: "20"
          # NO_PLAYWRIGHT: "1"
        run: |
          set -e
          python scraper/maxpreps_to_json.py \
            --date "${{ steps.args.outputs.date }}" \
            $([ -n "${{ steps.args.outputs.states }}" ] && echo --states "${{ steps.args.outputs.states }}") \
            --outdir data
          echo "==== List data/ ===="
          ls -lah data || true

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: .

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
    steps:
      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4
